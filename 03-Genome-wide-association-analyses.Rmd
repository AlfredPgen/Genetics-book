# Genome-wide association analysis

## DNA processing quality control

## Batch effects

https://www.bioconductor.org/packages/devel/bioc/vignettes/GWASTools/inst/doc/DataCleaning.pdf

The overall goal of this step is to check the quality of the sample batches. Substantial quality control is done by the genotyping centers prior to releasing the genotype data. However, it is possible that quality control for batches is still lower than desired. If a lower quality batch is detected then it may be necessary to re-run the genotyping for that batch. We can check the batch quality by comparing the missing call rates between batches and looking for significant allele frequency differences between batches.

### Missing call rate for samples and SNPs

The ﬁrst step is to calculate the missing call rates for each SNP and for each sample. A high missing call rate for a sample is often indicative of a poorly performing sample. It has been seen that samples from DNA that has undergone whole-genome ampliﬁcation (WGA) have a relatively higher missing call rate. Similarly a high missing call rate for a SNP is indicative of a problem SNP. Experience from the GENEVA studies has shown that there seem to be a subset of SNPs from which genotype calls are more diﬃcult to make than others. We calculate the missing call rates in a two step process: ﬁrst the missing call rates over all samples and SNPs are calculated, then the missing call rates are calculated again, ﬁltering out SNPs and samples that have an initial missing call rate greater than 0.05. The initial SNP missing call rate over all samples is saved in the SNP annotation data ﬁle as missing.n1. The analogous idea is applied to the samples: missing.e1 is saved in the sample annotation ﬁle and corresponds to the missing call rate per sample over all SNPs, excluding those SNPs with all calls missing. The missing.n2 is calculated as the call rate per SNP over all samples whose missing.e1 is less than 0.05. Again, similarly for the samples, missing.e2 is calculated for each sample over all SNPs with missing.n2 values less than 0.05. It is important to remember that the Y chromosome values should be calculated for males only, since we expect females to have no genotype values for the Y chromosome, although an occasional probe on the Y chromosome is called in a female.
If any samples have a high missing rate, we recommend further investigation of what may be causing the missing calls; the samples with a missing call rate greater than 0.05 should be ﬁltered out due to low sample quality.

### Missing call rates by batch

The missing call rate by batch is calculated to check that there are no batches with comparatively lower call rates. Usually a“batch”is a plate containing samples that were processed together through the genotyping chemistry. In this case all samples were run on diﬀerent plates (as controls for another dataset).

### Allele frequency differences across batches

In this step, the chi-square test for diﬀerences in allelic frequency is performed between each batch individually and a pool of all the other batches in the study. We then look at the mean χ<sup>2</sup> statistic over all SNPs for each batch as a function of the ethnic composition of samples in a batch.
Next we test for association between batches and population groups, using a χ<sup>2</sup> contingency test. Then we look at the relationship between the ethnic composition of each batch and the previously calculated χ<sup>2</sup> test of allelic frequency between each batch and a pool of the other batches. The point is to look for batches that diﬀer from others of similar ethnic composition, which might indicate a batch eﬀect due to genotyping artifact. In this experiment, there are only a few batches and wide variations in race among batches, so it is diﬃcult to interpret the results. In larger GWAS experiments, we generally observe a U-shaped curve of allelic frequency test statistic as a function of ethnic composition.
The χ<sup>2</sup> test is not suitable when the 2×2 tables for each SNP have very small values. For arrays in which many SNPs have very low minor allele frequency, Fisher’s exact test is more appropriate. 

## Sample quality control

### Cryptic relatedness

### Population stratification

Sometimes finding an association can be confounded by population stratification. This is because a condition may be more prevalent in one group of people than in a different group, resulting in a spurious association between the condition or trait being tested for and any genetic characteristics which vary between the two different groups of people.

While it is good practice for studies to be based on as homogeneous a group of test subjects as possible, it has been noted in [Price, 2006] that even the mild variation in genetic characteristics among those who classify themselves as belonging to one ethnic group or another can be problematic enough to confound a study done over thousands of genetic markers.

Hidden population stratification may be thought of as a non-zero F<sub>st</sub> between unknown groupings of samples.

### Heterozygosity and missingness outliers

### Differential missingness

### Sex chromosome anomalies

## Marker quality control

### Genotyping concordance

In genotyping studies where DNA is directly assayed for positions of variance, concordance is a measure of the percentage of SNPs that are measured as identical. Samples from the same individual or identical twins theoretically have a concordance of 100%, but due to assaying errors and somatic mutations, they are usually found in the range of 99% to 99.95%. Concordance can therefore be used as a method of assessing the accuracy of a genotyping assay platform.

### Mendelian errors

### Genotype call rate

### Minor allele frequency

### Hardy-Weinberg equilibrium outliers

### Additional QC for regions like MHC

### Ambigious nucleotides

If the base and target data were generated using different genotyping chips and the chromosome strand (+/-) for either is unknown, then it is not possible to match ambiguous SNPs (i.e. those with complementary alleles, either C/G or A/T) across the data sets, because it will be unknown whether the base and target data are referring to the same allele or not. While allele frequencies can be used to infer which alleles match, it is recommended to remove all ambiguous SNPs since the allele frequencies provided in base GWAS are often those from resources such as the 1000G project, and so aligning alleles according to their frequency could lead to systematic biases. 

### Non-matching nucleotides

When there is a non-ambiguous mismatch in allele coding between the data sets, such as A/C in the base and G/T in the target data, then this can be resolved by ‘flipping’ the alleles in the target data to their complementary alleles. 

### Quality control prior to meta-analysis

Allele Frequency Plots (AF Plots): looking for errors in allele frequencies and strand orientations by visually inspecting a plot of the sample allele frequency of filtered SNPs against the frequency in the 1000 Genomes phase 1 version 3 European panel3 for example.
P value vs Z-statistic Plots (PZ Plots): looking for the consistency between the reported P values and the P values implied by the coefficient estimates and standard errors in
individual cohort.
Quantile-Quantile Plots (QQ Plots): looking for the cohort-level QQ plots to look for evidence of unaccounted-for stratification.
Predicted vs Reported Standard-Error Plots (PRS Plots): making sure that the standard errors reported in individuals cohorts are approximately consistent with the reported sample size, allele frequency, and phenotype distribution. 
Use of bivariate LD score regression to verify that the estimated genetic correlations between all large cohorts (defined as N > 10,000) are large and positive.

## X-chromosome quality control

The X chromosome plays an important role in complex human traits and diseases, especially those with sexually dimorphic characteristics. Special attention needs to be given to the analysis of X due to its unique inheritance pattern and X-inactivation. These analytical complications have resulted in exclusion or mishandling of the X chromosome in the majority of genome-wide association studies (GWAS) to date.

## Single marker regression

Summary statistics can be obtained using one of the following tests: Correlation/Trend Test, Armitage Trend Test, Exact Form of Armitage Test, (Pearson) Chi-Squared Test, (Pearson) Chi-Squared Test with Yates’ Correction, Fisher’s Exact Test, Odds Ratio with Confidence Limits, Analysis of Deviance (e.g. different variance heterogeneity tests), F-Test, Logistic Regression, Linear Regression.

### Allelic test

### Genotypic test

### Additive model

Here, the genotype is coded in terms of the number of specific allele at a given locus.

### Dominant model

Here, the genotype with at least 1 copy of a specific allele at a given locus is coded as 1 and other genotypes as 0.

### Recessive model

Here, the genotype with at least 2 copies of a specific allele at a given locus is coded as 1 and other genotypes as 0.

### Categorical phenotype

### Multi-allelic GWAS

## Two-stage approach

## Haplotype GWAs design

## Joint analysis (all independent markers)

### Genomic control

In an ordinary GWAS, genomic control (GC) is used to shrink any existing inflation of the test scores (-log10 *p*-values). When testing for the single genetic effect in the GWAS, the null distribution of the test statistic for the nominal p-values is χ<sup>2</sup> with 1 degree of freedom. Since most of the SNPs are not expected to be associated with the trait, the sample distribution of the chi-squares across the genome should resemble the null distribution. If there is inflation, the chi-squares are adjusted using λ, i.e. the inflation factor estimated by comparing the distribution of the sample χ<sup>2</sup>’s and χ<sup>2</sup> distribution with 1 degree of freedom.

#### λ<sub>1000<sub>

Since λ scales with sample size, some have found it informative to report λ<sub>1000</sub>. This is equivalent to a study of 1000 cases and 1000 controls and can be calculated by rescaling λ with 1 + (λ - 1) x (1/case + 1/control) x 500, where case and control refers to the number of cases and controls respectively.

##### Stratified λ<sub>GC<sub>

Because the strength of λ<sub>GC</sub> deviation depends on allele frequency and very large sample sizes become available, it could be useful to report λ<sub>GC</sub> values based on certain MAF bins.

## Multimarker single gene-based approaches

https://cran.r-project.org/web/packages/aSPU/aSPU.pdf

## VEGAS

## Multimarker gene-set approaches (a.k.a. pathway analysis)

## fastBAT

## MAGMA

## VEGA

## Extensions to binary and categorical phenotypes

### Threshold model

## Analysis of rare variants

Check Lee et al (2014) for a review

Due to the low frequencies of rare variants, classical single marker tests commonly used in genome-wide association studies (GWAS) for studying common variants effects are not applicable.
In view of the lack of power of single marker analysis of rare variants, methods investigating rare variation are typically region-based tests where one tests for the cumulative effects of the rare variants in a region. These region-based methods can be broadly classified into three classes: burden tests, non-burden tests and hybrid of the two. The key difference between burden and non-burden tests is how the cumulative effects of the rare variants are combined for association testing. For the commonly used simple burden tests, one summarizes the rare variants within a region as a single summary genetic burden variable, e.g. the total number of rare variants in a region, and tests its association with a trait. Burden tests implicitly assume all the rare variants in the region under consideration are causal and are associated with the phenotype in the same direction and magnitude. Hence, they all share the limitation of substantial power loss when there are many non-causal genetic variants in a region and/or when there are both protective and harmful variants.
Several region-based non-burden tests have been proposed by aggregating marginal test statistics (Neale et al., 2011; Basu and Pan, 2011; Lin and Tang, 2011). One such test is the sequence kernel association test (SKAT) (Wu et al., 2011), where one summarizes the rare variants in the region using a kernel function, and then test for association with the trait of interest using a variance component score test. SKAT is robust to the signs and magnitudes of the associations of rare variants with a trait. It is more powerful than the burden tests when the effects are in different directions or the majority of variants in a region are null, but is less powerful than burden tests when most variants in a region are causal and the effects are in the same direction. Several hybrids of the two methods have been proposed to improve test power and robustness (Lee et al., 2012; Derkach et al., 2013; Sun et al., 2013).

### Collapsing methods based on pooling multiple rare variants (burden or adaptive burden tests)

#### Sum test

The most powerful multi-marker test when there are no causal variants with effects in opposite directions and when there are few or no non-causal RVs. Otherwise, it suffers from substantial loss of power.

#### Cohort Allelic Sums test (CAST)

#### Combined Multivariate Collapsing (CMC)

#### Weighted Sum test (WSS)

#### Kernel Based Adaptive Cluster (KBAC)

#### Replication Based Test (RBT)

#### ARIEL test

#### The EREC test

### Methods treating rare variant effects as random (Variance-component tests)

#### The SSU approach

Has good power in the presence of opposite association directions and small fraction of causal RVs.

#### C-alpha test

#### SKAT

Has good power in the presence of opposite association directions and non-causal RVs.
It was recently suggested that using SKAT in the presence of RVs and common variants (CVs) may be less optimal because RVs are weighted to have much more importance than CVs (Ionita-Laza et al., 2013). 

### Methods based on model selection

The model-selection approaches perform in the middle of random eﬀect and collapsing methods. One issue common to model-selection methods is that  model selection approaches use dimension-reduction strategies to substantially reduce the number of parameters one would require to ﬁt these large number of RVs. Hence, any model we can construct will never be the true model that generated the data we observe. In other words, the set of models is clearly misspeciﬁed, and model selection is best seen as a way of approximating, rather than identifying, full reality (Burnham and Anderson (2002), pp. 20-23).

#### Seq-aSum

#### Seq-aSum-VS

The Seq-aSum-VS approach classiﬁes RVs based on the direction of association (‘+1’ for positive association, ‘-1’ for negative association and ‘0’ for no association) and implements a sequential variable selection scheme to select the best model for association between the SNP-set and the disease. The only diﬀerence between the Seq-aSum approach and the Seq-aSum-VS approach is that the variable selection (‘0’ allocation for a variant) is not implemented in the former. The Seq-aSum-VS approach starts with putting all the RVs in the ‘+1’ group and proceeds by moving each RV sequentially to the other two groups and ﬁnally chooses the allocation (‘+1’,‘-1’, or ‘0’ ) with highest likelihood to the RV. The process of choosing the best model in Basu and Pan (2011)’s method can be compared to a stepwise regression, where one may not always ﬁnd the best model due to this selection scheme. This is especially true if a particular allocation results in a slightly higher likelihood than the other two allocations. In this case, choosing the allocation with highest likelihood for a SNP might not be optimal, rather it might be more eﬃcient to allow multiple allocations for a RV and construct a test that takes into account multiple plausible models for the disease-RV association. Moreover, the performance of the sequential search often depends on the ordering of the variants in this search mechanism. A model-averaging approach could potentially reduce the dependency on the ordering of the variants in this sequential search.

#### Variable Threshold Test (VT)

#### RARECOVER

#### Selective grouping method

#### Step-Up

### Combination of collapsing and random effects methods

According to Basu and Pan (2011), the model selection methods, especially Seq-aSum-VS approach, performed very well when there were both protective and deleterious causal RVs and very few non-causal RVs, but the performance of the Seq-aSum-VS approach was not very impressive in the presence of a moderate or large number of non-causal RVs. These and other ﬁndings (Basu and Pan, 2011) have led to combining the strengths of collapsing and random eﬀect methods.

#### SKAT-O

#### SKAT-C

#### Fisher method

#### MiST

### EC test

Exponentially combines score statistics. Powerful when a very small proportion of variants are causal.

### Family-based tests

https://www.omicsonline.org/open-access/literature-reviews-on-methods-for-rare-variant-association-studies-2161-0436-1000133.pdf

## Analysis of X, Y and mitochondrial chromosomes

### Dosage compensation

## Analysis of copy number variants

### Common variation

### Analysis of rare variants

## Analysis of multi-ethnic samples

## Analysis of indirect genetic effects

## Exome analysis

## Whole-genome analysis

### Deep whole genome sequencing

Currently is applied to limited numbers of samples.
Provides most complete ascertainment of variation.

### Low coverage whole genome sequencing

Can be applied to moderate numbers of samples
Very complete ascertainment of shared variation
Less complete ascertainment of rare variants

## Analysis of multiple traits

## Mixed-model association analysis

GWAS using mixed models is appealing for several reasons:
1) More powerful in very large GWAS
2) Reduces the need for sample exclusion
3) Amplifies effective sample sizes via conditioning on polygenic predictions from genome-wide SNPs.

When using mixed models for association analysis, care must be taken to consider non-additive effects when retaining related individuals.

### EMMAX

### Fast-LMM

### GEMMA

### BOLT-LMM

When BOLT-LMM was used on very large sample sizes, analyses revealed subtleties in the interpretation of LD score regression intercepts as a means of differentiating polygenicity from confounding; the attenuation ratio was proposed to be possibly a more suitable metric as sample sizes increase.

## SAIGE

### Caveats

First, chi-squared-based tests (such as BOLT-LMM) can incur inflated type I error rates when used to analyze highly unbalanced case–control traits (case fractions <10%). There are two solutions for this.
1) Increase MAF.
2) Use saddlepoint approximation (SAIGE software).

Second, conditioning on genome-wide signal can produce loss of power under case–control ascertainment.

## Extension to unusual phenotypes

### Multinomial GWAS

### Ordinal GWAS

### Survival GWAS

## Penalized regression GWAS

## Bayesian GWAS

## Machine learning for GWAS

## Expected increase in GWAS loci with sample size

## The joint effect of genotypes over all traits

## Adjustment for winner's curse

One type of adjustment for winer's curse (using empirical Bayes), depends on the assumption that SNP effects are drawn randomly from the following mixture distribution 

## Adjustment for assortative mating

## Adjustment for attenuation bias

LD score regression

## Enrichment in candidate genes

Atwell et al. (2010) introduced a method for evaluating the enrichment of strong, but not necessarily genome-wide significant, signals for SNPs in candidate genes. An enrichment of such signals indicates that the analysis identifies true signals rather than random noise.

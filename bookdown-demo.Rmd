--- 
title: "A handbook for Computational Genetics"
author: "Alfred Pozarickij"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: rstudio/bookdown-dem
description: "This is the book describing theoretical and practical approaches in analysis of genome data."
---

# Preface {-}

The scope of this book is to provide an outline of computational methods available for the analysis of genetic data.

First chapter introduces methods to infer population parameters. 

Next X chapters focus on population genetics.

In this book, the amount of mathematics and statistics is kept to a minimum. Only methods designed specifically to address issues in genetics are shown. I have produced another book [insert link here], which is intended to familiarise the reader with commonly used approaches and develop some intuition behind them. By no means the list is comprehensive and only serves as a quick guide. The internet provides much more information regarding this topic.

Rather than providing references at the end of each chapter, I decided to combine them into supplementary text [insert link here]. References are arranged according to different topics discussed in this book. I tried to do my best to cause as little confusion as possible.

Finally, don't hesitate to contact me if I have not included your favorite method (apozarickij@gmail.com). I would be more than happy to hear about it.








<!--chapter:end:index.Rmd-->

# (PART) Quantitative Genetics {-}

# Population parameters

## Mean

## Variance

## Covariance

## Genetic correlation

## Additivity

## Dominance/Recesivness

## Codominance

## Infinitesimal model

### Omnigenic model

## Henetic relationships by Malecot


## Genotype simulations

## Phenotype simulations

<!--chapter:end:01-Descriptives.Rmd-->

# Sequencing technologies

The first step in any genetic analysis is to map sequence reads, callibrate base qualities, and call variants. 

Prior to mapping, evaluate base composition along reads. Calculate the proportion of A, C, G, T bases along each read. Flag runs with evidence of unusual patterns of base composition compared to the target genome.
Evaluate machine quality scores along reads. Calculate average quality scores per position. Flag runs with evidence of unusual quality score distributions.
Calculate the input number of reads and number of bases for each sequenced sample

## Genotype calling algorithms

## Sequence alignment

Sequence alignment is a method of arranging sequences of DNA, RNA, or protein to identify regions of similarity. The similarity being identified, may be a result of functional, structural, or evolutionary relationships between the sequences.

If we compare two sequences, it is known as pairwise sequence alignment. If we compare more than two sequences, it is known as multiple sequence alignment.

## Sequence assembly

## SNP annotation

### CNV annotation

## Gene prediction



<!--chapter:end:02-Sequencing-technologies.Rmd-->

# Genome-wide association analysis

## DNA processing quality control

## Batch effects

https://www.bioconductor.org/packages/devel/bioc/vignettes/GWASTools/inst/doc/DataCleaning.pdf

The overall goal of this step is to check the quality of the sample batches. Substantial quality control is done by the genotyping centers prior to releasing the genotype data. However, it is possible that quality control for batches is still lower than desired. If a lower quality batch is detected then it may be necessary to re-run the genotyping for that batch. We can check the batch quality by comparing the missing call rates between batches and looking for significant allele frequency differences between batches.

### Calculation of missing call rate for samples and SNPs

The ﬁrst step is to calculate the missing call rates for each SNP and for each sample. A high missing call rate for a sample is often indicative of a poorly performing sample. It has been seen that samples from DNA that has undergone whole-genome ampliﬁcation (WGA) have a relatively higher missing call rate. Similarly a high missing call rate for a SNP is indicative of a problem SNP. Experience from the GENEVA studies has shown that there seem to be a subset of SNPs from which genotype calls are more diﬃcult to make than others. We calculate the missing call rates in a two step process: ﬁrst the missing call rates over all samples and SNPs are calculated, then the missing call rates are calculated again, ﬁltering out SNPs and samples that have an initial missing call rate greater than 0.05. The initial SNP missing call rate over all samples is saved in the SNP annotation data ﬁle as missing.n1. The analogous idea is applied to the samples: missing.e1 is saved in the sample annotation ﬁle and corresponds to the missing call rate per sample over all SNPs, excluding those SNPs with all calls missing. The missing.n2 is calculated as the call rate per SNP over all samples whose missing.e1 is less than 0.05. Again, similarly for the samples, missing.e2 is calculated for each sample over all SNPs with missing.n2 values less than 0.05. It is important to remember that the Y chromosome values should be calculated for males only, since we expect females to have no genotype values for the Y chromosome, although an occasional probe on the Y chromosome is called in a female.
If any samples have a high missing rate, we recommend further investigation of what may be causing the missing calls; the samples with a missing call rate greater than 0.05 should be ﬁltered out due to low sample quality.

### Calculation of missing call rates by batch

The missing call rate by batch is calculated to check that there are no batches with comparatively lower call rates. Usually a“batch”is a plate containing samples that were processed together through the genotyping chemistry. In this case all samples were run on diﬀerent plates (as controls for another dataset).

### Testing for allele frequency differences in batches

In this step, the chi-square test for diﬀerences in allelic frequency is performed between each batch individually and a pool of all the other batches in the study. We then look at the mean χ<sup>2</sup> statistic over all SNPs for each batch as a function of the ethnic composition of samples in a batch.
Next we test for association between batches and population groups, using a χ<sup>2</sup> contingency test. Then we look at the relationship between the ethnic composition of each batch and the previously calculated χ<sup>2</sup> test of allelic frequency between each batch and a pool of the other batches. The point is to look for batches that diﬀer from others of similar ethnic composition, which might indicate a batch eﬀect due to genotyping artifact. In this experiment, there are only a few batches and wide variations in race among batches, so it is diﬃcult to interpret the results. In larger GWAS experiments, we generally observe a U-shaped curve of allelic frequency test statistic as a function of ethnic composition.
The χ<sup>2</sup> test is not suitable when the 2×2 tables for each SNP have very small values. For arrays in which many SNPs have very low minor allele frequency, Fisher’s exact test is more appropriate. 

## Sample quality control

### Cryptic relatedness

### Population stratification

Sometimes finding an association can be confounded by population stratification. This is because a condition may be more prevalent in one group of people than in a different group, resulting in a spurious association between the condition or trait being tested for and any genetic characteristics which vary between the two different groups of people.

While it is good practice for studies to be based on as homogeneous a group of test subjects as possible, it has been noted in [Price, 2006] that even the mild variation in genetic characteristics among those who classify themselves as belonging to one ethnic group or another can be problematic enough to confound a study done over thousands of genetic markers.

Hidden population stratification may be thought of as a non-zero F<sub>st</sub> between unknown groupings of samples.

### Heterozygosity and missingness outliers

### Differential missingness

### Sex chromosome anomalies

## Marker quality control

### Genotyping concordance

In genotyping studies where DNA is directly assayed for positions of variance, concordance is a measure of the percentage of SNPs that are measured as identical. Samples from the same individual or identical twins theoretically have a concordance of 100%, but due to assaying errors and somatic mutations, they are usually found in the range of 99% to 99.95%. Concordance can therefore be used as a method of assessing the accuracy of a genotyping assay platform.

### Mendelian errors

### Genotype call rate

### Minor allele frequency

### Hardy-Weinberg equilibrium outliers

### Additional QC for regions like MHC

### Ambigious nucleotides

### Non-matching nucleotides

## X-chromosome quality control

## Single marker regression

Summary statistics can be obtained using one of the following tests: Correlation/Trend Test, Armitage Trend Test, Exact Form of Armitage Test, (Pearson) Chi-Squared Test, (Pearson) Chi-Squared Test with Yates’ Correction, Fisher’s Exact Test, Odds Ratio with Confidence Limits, Analysis of Deviance (e.g. different variance heterogeneity tests), F-Test, Logistic Regression, Linear Regression.

### Allelic test

### Genotypic test

### Additive model

Here, the genotype is coded in terms of the number of specific allele at a given locus.

### Dominant model

Here, the genotype with at least 1 copy of a specific allele at a given locus is coded as 1 and other genotypes as 0.

### Recessive model

Here, the genotype with at least 2 copies of a specific allele at a given locus is coded as 1 and other genotypes as 0.

### Categorical phenotype

### Multi-allelic GWAS

## Two-stage approach

## Haplotype GWAs design

## Joint analysis (all independent markers)

### Genomic control

#### λ<sub>1000<sub>

Since λ scales with sample size, some have found it informative to report λ<sub>1000</sub>. This is equivalent to a study of 1000 cases and 1000 controls and can be calculated by rescaling λ with 1 + (λ - 1) x (1/case + 1/control) x 500, where case and control refers to the number of cases and controls respectively.

## Multimarker single gene-based approaches

https://cran.r-project.org/web/packages/aSPU/aSPU.pdf

## VEGAS

## Multimarker gene-set approaches (a.k.a. pathway analysis)

## fastBAT

## MAGMA

## VEGA

## Extensions to binary and categorical phenotypes

### Threshold model

## Analysis of rare variants

Check Lee et al (2014) for a review

Due to the low frequencies of rare variants, classical single marker tests commonly used in genome-wide association studies (GWAS) for studying common variants effects are not applicable.
In view of the lack of power of single marker analysis of rare variants, methods investigating rare variation are typically region-based tests where one tests for the cumulative effects of the rare variants in a region. These region-based methods can be broadly classified into three classes: burden tests, non-burden tests and hybrid of the two. The key difference between burden and non-burden tests is how the cumulative effects of the rare variants are combined for association testing. For the commonly used simple burden tests, one summarizes the rare variants within a region as a single summary genetic burden variable, e.g. the total number of rare variants in a region, and tests its association with a trait. Burden tests implicitly assume all the rare variants in the region under consideration are causal and are associated with the phenotype in the same direction and magnitude. Hence, they all share the limitation of substantial power loss when there are many non-causal genetic variants in a region and/or when there are both protective and harmful variants.
Several region-based non-burden tests have been proposed by aggregating marginal test statistics (Neale et al., 2011; Basu and Pan, 2011; Lin and Tang, 2011). One such test is the sequence kernel association test (SKAT) (Wu et al., 2011), where one summarizes the rare variants in the region using a kernel function, and then test for association with the trait of interest using a variance component score test. SKAT is robust to the signs and magnitudes of the associations of rare variants with a trait. It is more powerful than the burden tests when the effects are in different directions or the majority of variants in a region are null, but is less powerful than burden tests when most variants in a region are causal and the effects are in the same direction. Several hybrids of the two methods have been proposed to improve test power and robustness (Lee et al., 2012; Derkach et al., 2013; Sun et al., 2013).

### Collapsing methods based on pooling multiple rare variants (burden or adaptive burden tests)

#### Sum test

The most powerful multi-marker test when there are no causal variants with effects in opposite directions and when there are few or no non-causal RVs. Otherwise, it suffers from substantial loss of power.

#### Cohort Allelic Sums test (CAST)

#### Combined Multivariate Collapsing (CMC)

#### Weighted Sum test (WSS)

#### Kernel Based Adaptive Cluster (KBAC)

#### Replication Based Test (RBT)

#### ARIEL test

#### The EREC test

### Methods treating rare variant effects as random (Variance-component tests)

#### The SSU approach

Has good power in the presence of opposite association directions and small fraction of causal RVs.

#### C-alpha test

#### SKAT

Has good power in the presence of opposite association directions and non-causal RVs.
It was recently suggested that using SKAT in the presence of RVs and common variants (CVs) may be less optimal because RVs are weighted to have much more importance than CVs (Ionita-Laza et al., 2013). 

### Methods based on model selection

The model-selection approaches perform in the middle of random eﬀect and collapsing methods. One issue common to model-selection methods is that  model selection approaches use dimension-reduction strategies to substantially reduce the number of parameters one would require to ﬁt these large number of RVs. Hence, any model we can construct will never be the true model that generated the data we observe. In other words, the set of models is clearly misspeciﬁed, and model selection is best seen as a way of approximating, rather than identifying, full reality (Burnham and Anderson (2002), pp. 20-23).

#### Seq-aSum

#### Seq-aSum-VS

The Seq-aSum-VS approach classiﬁes RVs based on the direction of association (‘+1’ for positive association, ‘-1’ for negative association and ‘0’ for no association) and implements a sequential variable selection scheme to select the best model for association between the SNP-set and the disease. The only diﬀerence between the Seq-aSum approach and the Seq-aSum-VS approach is that the variable selection (‘0’ allocation for a variant) is not implemented in the former. The Seq-aSum-VS approach starts with putting all the RVs in the ‘+1’ group and proceeds by moving each RV sequentially to the other two groups and ﬁnally chooses the allocation (‘+1’,‘-1’, or ‘0’ ) with highest likelihood to the RV. The process of choosing the best model in Basu and Pan (2011)’s method can be compared to a stepwise regression, where one may not always ﬁnd the best model due to this selection scheme. This is especially true if a particular allocation results in a slightly higher likelihood than the other two allocations. In this case, choosing the allocation with highest likelihood for a SNP might not be optimal, rather it might be more eﬃcient to allow multiple allocations for a RV and construct a test that takes into account multiple plausible models for the disease-RV association. Moreover, the performance of the sequential search often depends on the ordering of the variants in this search mechanism. A model-averaging approach could potentially reduce the dependency on the ordering of the variants in this sequential search.

#### Variable Threshold Test (VT)

#### RARECOVER

#### Selective grouping method

#### Step-Up

### Combination of collapsing and random effects methods

According to Basu and Pan (2011), the model selection methods, especially Seq-aSum-VS approach, performed very well when there were both protective and deleterious causal RVs and very few non-causal RVs, but the performance of the Seq-aSum-VS approach was not very impressive in the presence of a moderate or large number of non-causal RVs. These and other ﬁndings (Basu and Pan, 2011) have led to combining the strengths of collapsing and random eﬀect methods.

#### SKAT-O

#### SKAT-C

#### Fisher method

#### MiST

### EC test

Exponentially combines score statistics. Powerful when a very small proportion of variants are causal.

### Family-based tests

https://www.omicsonline.org/open-access/literature-reviews-on-methods-for-rare-variant-association-studies-2161-0436-1000133.pdf

## Analysis of X, Y and mitochondrial chromosomes

### Dosage compensation

## Analysis of copy number variants

### Common variation

### Analysis of rare variants

## Analysis of multi-ethnic samples

## Analysis of indirect genetic effects

## Exome analysis

## Whole-genome analysis

### Deep whole genome sequencing

Can only be applied to limited numbers of samples
Most complete ascertainment of variation

### Low coverage whole genome sequencing

Can be applied to moderate numbers of samples
Very complete ascertainment of shared variation
Less complete ascertainment of rare variants

## Analysis of multiple traits

## Mixed-model association analysis

### EMMAX

### Fast-LMM

### GEMMA

### BOLT-LMM

## Penalized regression GWAS

## Bayesian GWAS

## Machine learning for GWAS

## Expected increase in GWAS loci with sample size

## The joint effect of genotypes over all traits



<!--chapter:end:03-Genome-wide-association-analyses.Rmd-->

# Heritability

## Realized heritability

### Evolvability

### Reliability

## Twin studies

## Haseman-Elston regression

## GREML

## GREML in family data

## GREML in WGS or imputed data

### GREMLd

### Bivariate GREML

## LD-score regression

## LDAK

## Heritability by chromosome, MAF bin, or functional category


<!--chapter:end:04-Heritability.Rmd-->

# Genomic prediction

## Unweighted sum of risk alleles

## Polygenic risk scores

## Gene-based polygenic score (POLARIS)

## Pathway-based polygenic risk score

## LD adjusted PRS

### LDpred with functional annotation

## Annopred

## Pleiopred

## Prediction including GxE

## BLUP

### GBLUP

### sBLUP

## Bayesian Zoo

### B

### C

### S

### N

### NS

### R

## Reproducing kernel Hilbert space

## Machine learning methods


<!--chapter:end:05-Genomic-prediction.Rmd-->

# Pleiotropy

## Fisher's geometric model

## Direct

## Indirect


<!--chapter:end:06-Pleiotropy.Rmd-->

# Pathway-analysis

<!--chapter:end:07-Pathway-analysis.Rmd-->

# Functional annotation

<!--chapter:end:08-Functional-annotation.Rmd-->

# Causal inference

## Gene-knockout

## Conditioning

Adding additional SNPs as covariates

## COJO

## mtCOJO

## Finemapping

## Mendelian Randomization

Mendelian Randomization relies on three assumptions about the instruments:

1) They must be sufficiently strongly associated with the exposure.
2) They should not be associated with any confounder of the exposure-outcome relationship.
3) They should be associated with the outcome only through the exposure.

Violation of any ofthese assumptions often through pleiotropy  would lead to biased estimates of the causal effect and potential false positives. The second assumption is the most difficult to verify because confounding factors are often unknown, whereas the last assumption can only be partially verified at best if SNPs, exposures and outcome data are available from the same (large) sample, a condition not fulfilled for two-sample MR.

These assumptions imply that the genetic variants (IVs) have a causal effect on the outcome only via the risk factor. While the first assumption can be easily verified, the second one is impossible to confirm as not all confounders are known, and the third requires instrument-exposure-outcome data measured in the same sample and is often violated by pleiotropy. One (ideal) way to guard against the violation of the third assumption is to use as many IVs possible, as the pleiotropic effect of each marker will cancel each other out under the INSIDE assumption (instrument strength independent of the strength of the pleiotropy).

Cochran’s Q test can be used in order to test for the presence of pleiotropy.

### Summary data-based MR (SMR)

SMR can be used to test whether the effects of genetic variants on a phenotype are mediated by gene expression. The method is based on a single genetic variant.

### Generalised summary-data-based MR (GSMR) and HEIDI

GSMR was developed to overcome the issue of unaccounted pleiotropy in SMR method. This method performs a MR analysis with multiple independent SNPs as instrumental variables. 

### Joint analysis of GWAS and eQTL data

It is common in GWAS studies to identify variants that are located in genomic regions thought to be involved in regulation of gene expression. In order to improve power from GWAS studies, a method involving joint analysis of GWAS and eQTL data was proposed. This approach superceeds previous TWAS methods by allowing to account for pleiotropy in a Mendelian Randomization framework.

Two things are needed in order to carry out this test: summary-level data and pair-wise SNP LD information.

The method was developed after realisation that many pleiotropic effects are mediated through the expression levels of neighbouring genes; hence including other genes as exposures should reduce MR assumption violation, while improving power. Furthermore, such approach might be able to better distinguish the causal effects of genes with correlated expression levels.

As any other method, this approach suffers from several limitations:

1) The putative causal associations reported in this study are not definitive. They provide a prioritized list of candidate genes for future follow-up studies and also shed light on possible biological mechanisms of complex traits.

2) Currently, eQTL data is available for 15K egenes, which substantially decreases power to detect enrichment of prioritized gene-set in relevant pathways and regulatory networks.

3) Violations of MR assumptions. In particular, horizontal pleiotropy and indirect effects of the instruments on the exposures can substantially bias causal effect estimates.

Because the study requires summary statistics and LD pattern, it is possible to extend the method to include other omics information.

### Tissue-specific MR

Since many traits manifest themselves only in certain tissues, it is important to integrate data from the tissue of interest for the studied phenotype when trying to interpret GWAS results using gene expression as an intermediate phenotype. 


<!--chapter:end:09-Inferring-causality.Rmd-->

# Combining multiple datasets

## Meta-analysis

### Meta-analysis of gene-level associations (common)?

### Meta-analysis of rare variants

RAREMETAL and RAREMETALWORKER

## Mega-analysis

<!--chapter:end:10-Analysis-of-multiple-datasets.Rmd-->

# Gene-environment interaction

It is generally accepted that complex diseases are caused by an interplay of genetic and environmental factors, creating a challenge for understanding the disease mechanisms. Understanding the interplay between genes and environmental factors is important, as genes do not operate in isolation but rather in complex networks and pathways influenced by environmental factors.
Identification of gene-environment interactions has important implications for understanding underlying disease etiology and developing disease prevention and intervention strategies.
In addition to providing insights into disease etiology, exploiting gene-environment (G-E) interaction can help discover novel susceptibility loci for complex diseases, where genetic effects are modified and masked by the effects of environmental factors.
From a public health perspective, G-E interaction is useful because findings based on interactions can help develop strategies for targeted intervention; conducting an intervention focusing on a subset of the population identified by G-E interactions can provide efficiency in disease prevention.
There are several challenges of G-E interaction analysis that include replication issues. While more powerful statistical methods for detecting interactions are helpful, ultimately studies with larger sample sizes are needed to identify interactions through consortium-based studies to achieve adequate power for G-E analysis.

This chapter aims to describe methods that extend single marker regression by taking into consideration the effect of gene-environment interaction.

## Single step methods

There are several disease risk models for the joint effects of G and E, and interpretations of G-E interactions depend on the underlying disease risk models.

### Case-control

### Prospective likelihood-based approach

### Retrospective likelihood approach

To address the limitations of case-only approaches that can only test for multiplicative interactions (not for the main effects of G and E), Umbach and Weinberg (1997) generalized the case-only design idea to use a log-linear model based on case-control data. They showed the maximum-likelihood estimates for all parameters of a logistic regression model can be obtained using a log-linear model. Along the same line, Chatterjee and Carroll developed a general method using a retrospective likelihood that exploits the G-E independence assumption to test for multiplicative interaction, but can use both cases and controls to estimate all of the parameters in a general logistic regression model. Basically, this method employs a retrospective likelihood that explicitly models the conditional probability of G given E mediated by an association parameter θ that can be constrained to be zero when the G-E independence assumption holds. This likelihood can be used for testing both multiplicative and additive interactions; recently, Han et al. developed a likelihood ratio test that exploits the G-E independence assumption using a retrospective likelihood. Their numerical investigation of power suggests that the incorporation of the independence assumption can enhance the efficiency of the test for additive interaction by 2- to 2.5-fold.

#### Multiplicative scale

A multiplicative model incorporating GxE effects is one of the most commonly used models via logistic regression: logit(Pr(*D* = 1|*G*,*E*)) = *β<sub>o</sub>* + *β<sub>g</sub>G* + *β<sub>e</sub>E* + *β<sub>ge</sub>GE*, where *G* is a genotype of a SNP, *E* is an environmental risk factor, and *D* is the disease status. 

Assuming binary factors for both G and E, a 2 × 2 table for a disease risk for each combination of G and E values can be constructed based on this model (Table X).

#### Additive scale

An additive model is shown as logit(Pr(*D* = 1|*G*,*E*)) = *b<sub>o</sub>* + *b<sub>g</sub>G* + *b<sub>e</sub>E* + *b<sub>ge</sub>GE*, where the effects of G and E are additive on the disease risk scale, but not on the logit scale. 

### Case-only

This design depends on an assumption of G–E independence in the underlying population. Under the assumption of G-E independence in the underlying population (i.e., controls), a multiplicative interaction test statistic becomes equivalent to testing the association between G and E among cases. One major limitation of the case-only design is that while the case-only method has improved power over the traditional methods when G and E are independent in the underlying population, this method has an increased type I error if the independence assumption is violated. In addition, the regression parameters for the main effects of G and E cannot be estimated using this method because the case-only test is only for evaluating a multiplicative interaction.

### Empirical Bayes and Bayesian Model Averaging

## GxE in the context of family studies

## Multi stage methods

Several approaches exist. In general, these methods suggest selecting a subset of SNPs based on the marginal effects of SNPs or G-E correlation tests in the first stage and conducting standard G-E interaction tests in the second stage, where the independence between the test statistics used in the two stages is required to provide a valid screening procedure.

For calculating power for G-E interactions, the powerGWASinteraction R package is available (https://cran.r-project.org/web/packages/powerGWASinteraction/index.html), which includes a power calculation tool for four two-stage screening and testing procedures.

## Joint tests

### Gene-based

## Set-based interaction tests

There are multiple reasons for using set-based gene-environment interaction tests. 

1. Multiple comparison adjustments for a large number of markers across the genome could result in power loss.
2. Closely located SNPs are correlated because of linkage disequilibrium. Multiple tests for GxE in these single-marker-based GxE models are even more dependent, as interaction terms in these models share the same environmental variable. Dependence among multiple tests can result in incorrect Type 1 error rates and causes bias in standard multiple comparison adjustments and this bias is often difficult to correct.
3. The single-marker GxE test does not interrogate the joint effects of multiple SNPs that have similar biological functions. When the main effects of multiple SNPs in a set are  associated with a disease/trait, the classical single marker regression interaction test can be biased.

Lin et al. (2013) developed a method to analyse GxE for a set of markers using generalized linear mixed models. The method tests for SNP-set by environment interactions using a variance component test, and because a set of variants will likely be correlated, the main SNP effect estimates under the null hypothesis are obtained using ridge regression. 
Their software is called GESAT. Here, they model GxE effects as random, as opposed to the classical approach of treating *β<sub>j</sub>*’s as fixed effects followed by a test with *p* degrees of freedom. The latter approach can suffer from power loss when *p* is moderate/large, and numerical difficulties when some genetic markers in the set are in high LD. 
The model allows to adjust for the main effects of all SNPs while simultaneously testing for the interactions between the SNPs in the region and environmental variable. For unbalanced designs when a binary environmental exposure has a low frequency in one category, GESAT is most advantageous over single marker regression GxE test. Such unbalanced designs can occur due to case–control sampling and the strong association of an environmental factor with disease. When the effect size is modest, GESAT performs better that single marker regression GxE test, but when the effect size is strong, the opposite is true. 
Their simulations suggest that the power of GESAT seems fairly robust to the dependence between G and E.

The same approach can be applied to investigating various other biological problems. For example, we can test for the interactions between gene expressions in a pathway or network and an environmental variable by simply replacing G by gene expressions in a gene-set.

Existing methods for assessing common variants by environment interactions such as Gene-Environment Set Association Test (GESAT) (Lin et al., 2013) have several limitations when applied for rare variants. GESAT estimates the main effects of the common variants by applying a L<sub>2</sub> penalty on the genotypes scaled to unit variance; this assumes that the main effects of the scaled genotypes are comparable in magnitudes, which may not hold in the case of rare variants. GESAT also assumes that the regression coefficients of the rare variants by environment interactions are independent of each other, and suffers from power loss when most rare variants in a gene interact with the environmental factor and the interaction effects have the same direction.

Similar idea from GESAT was later extended and applied to analyse rare variants. GESAT have several limitations when applied for rare variants. GESAT estimates the main effects of the common variants by applying a L<sub>2</sub> penalty on the genotypes scaled to unit variance; this assumes that the main effects of the scaled genotypes are comparable in magnitudes, which may not hold in the case of rare variants. GESAT also assumes that the regression coefficients of the rare variants by environment interactions are independent of each other, and suffers from power loss when most rare variants in a gene interact with the environmental factor and the interaction effects have the same direction. The new proposed test iSKAT is optimal in a class of variance component tests and is powerful and robust to the proportion of variants in a gene that interact with environment and the signs of the effects. This test properly controls for the main effects of the rare variants using weighted ridge regression while adjusting for covariates.

A naive approach to assess rare variants by environment interactions is to extend the burden test by fitting a model with both the summary genetic burden variable, environment, and their interaction, and performing a one degree of freedom test for the interaction. However, when there are multiple causal variants with their main effects having different magnitudes and/or signs, such a burden rare variant by environment test fails, and may lead to inflated Type 1 error rates. This is because adjusting for the main effects of the multiple causal variants using a single summary genetic burden variable is inappropriate. Likewise, a naive approach to assess rare variants by environment interactions using SKAT by including the main effects of rare variants as part of covariates and applying SKAT to the interaction terms is problematic. This is because SKAT only allows adjustment of a small number of covariates and cannot handle the presence of a large number of rare variants in a region. Furthermore since the rare variants are observed in low frequency, a model with all the rare variants as main effects will be highly unstable and may not even converge.

Both GESAT and iSKAT are able to incorporate multiple environmental variables.

No gene-based GxE test exists for the analysis of the sex chromosomes as of writing this text.

The rareGE R package (https://www.hsph.harvard.edu/han-chen/software/) provides various functions for detecting G-E interaction as well as for testing the joint effect of a gene and G-E interaction under a set-based framework. 
The SIMreg R package (http://www4.stat.ncsu.edu/~jytzeng/software_simreg.php) offers functions for testing a set-based G-E interaction by using genetic similarity to aggregate information across SNPs, and incorporating adaptive weights depending on allele frequencies to accommodate rare and common variants.

https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.12428

https://academic.oup.com/biostatistics/article-abstract/18/1/119/2555344?redirectedFrom=fulltext

## Combining multiple environments

### Multi-trait multi-GxE tests

## Variance heterogeneity

All methods described in this chapter so far conduct a location (mean) based test. In other words, the main concern is whether there is a difference in mean effect between different genotypes. Testing for scale (variance) heterogeneity, prior to the main inference of location parameters, is additional method to evaluate the assumption of homoscedasticity in linear regression. This is true when the interacting variable was not collected and the interaction term may not be directly modeled or when a phenotype was transformed. Therefore, the analysis of variances of the trait is based on SNP information only.

Presence of interaction between a genotype and certain factor is expected to alter the trait's variance in the group of subjects carrying such genotype.

Can the shift in variance be caused by multi-allelic loci?

### Levene's test

Levene’s test (Levene, 1960) is known for its simplicity and robustness to modeling assumptions, and it is perhaps the most popular method for evaluating variance heterogeneity between k groups. More recently it has been employed as an indirect test for interaction effects.

### Bartlett's test

$T^2 = \frac{(N-k) \sum_{j=0}^{k-1} n_j(Z_j.-Z_..)^2}{(k-1)\sum_{i=1}^{N}(Z_i-Z_gi.)}$


### Bartlett's test with prior rank transformation to normality

### Generalized Levene's scale tests

The Levene's test for variance heterogeneity was later expanded to include sample correlation and group membership uncertainty (genotype imputation probabilities). Following a two-stage regression framework, it was shown that the least absolute deviation regression must be used in the stage 1 analysis to ensure a correct asymptotic χ<sup>2</sup><sub>k−1</sub>/(k−1) distribution of the generalized scale (gS) test statistic. 

gS has good type 1 error control in the presence of sample correlation, small samples, unbalanced group sizes, and non-symmetric outcome data.

Same study showed that the least absolute deviation (LAD) regression approach to obtain group-median-adjusted residuals is needed to ensure robust performance of gS (and possibly LAD should be used in all scale dependent tests).

Several improvements including adjustment for covariates could be further explored (check original paper)

### Two-step screening on residual variance heterogeneity

#### VH

#### YGVH


One caviet involving VH tests is that the absence of VH for a SNP can not be interpreted as the absence of the SNP involvment of the SNP in the interaction network.

### Conditional quantile regression 

In contrast to OLS regression, quantile regression tests for the effect differences across the range of quantiles. More specifically, conditional quantile regression (CQR), can be used to model effect size changes across the sample distribution. This method is similar to other varaince heterogeneity methods in a way that does not require interacting effects to be known and hence included in the model. The downside of this is that further investigation is required to identify environmental factors causing statistical interactions.

### Sliced inverse regression

Jiang and Liu, 2014

### Variance heterogeneity for related individuals

## RELIEF and other machine learning tools

### Multidimensionality reduction

## Meta-analytic GxE approaches

## Gene-environment correlation

## Other challanges

There are several challenges of G-E interaction analysis. One main challenge is replication issues. While various GWAS findings of the main effects of SNPs have been replicated by independent studies for many complex diseases (http://www.ebi.ac.uk/gwas/), relatively few interactions have been reproduced. It is likely that the sample sizes of GWAS that have required measurements on environmental exposures are not yet adequate to reliably identify G-E interactions of modest magnitude. In addition, differences in the underlying distribution of environmental exposures across various studies as well as difficulties in accurately measuring environmental exposures can also lead to reduced power of detecting G-E interactions. While more powerful statistical methods for detecting interactions are helpful, ultimately studies with larger sample sizes are needed to identify interactions (e.g., through consortium-based studies) to achieve adequate power for G-E analysis. A reasonable goal for the future will be to at least identify parsimonious models that adequately describe the risks of diseases associated with a combination of genetic and environmental risk factors. The lack of reporting of interaction in current studies so far indicates that linear logistic models, i.e., multiplicative models, in general may be a good starting point for building models for evaluating the joint effects of genetic and environmental factors.



<!--chapter:end:11-GxE.Rmd-->

# Gene-gene interaction

When the combined phenotypic effect of alleles at two or more loci deviates from the sum of their individual effects, this is referred to as a genetic interaction, or epistasis. 
There are some situations where data and theory have suggested that it might be particularly important to account for genetic interactions. One is when the aim is to predict the phenotypes of individuals on the basis of their genotype. If interactions lead to extreme phenotypes for some genotypes, these phenotypes are unlikely to be captured by additive models, particularly if they are rare. Another case is the prediction of long-term selection response. Under an additive model, both the additive variance and the response are expected to be nearly constant over the first few generations. As generations proceed, allele frequencies change to alter the additive variance and, consequently, the response to selection. This change is more rapid for traits regulated by fewer loci with larger effects than for traits regulated by many loci with smaller effects. It is known that genetic interactions can contribute to the additive genetic variance in a population. The contribution, however, varies depending on the joint allele frequencies across all the interacting loci as well as on the types and strengths of the genetic interactions. The changes in the additive variance, and hence the response, during ongoing selection are therefore more complex in the presence of genetic interactions.

Most genetic variance in a population is expected to be additive even in the presence of extensive epistasis. The lack of empirical knowledge about the pervasiveness and strength of epistasis in the genetic architectures of complex traits makes it largely unknown how much of the observed additive genetic variance in quantitative genetics studies is due to genetic interactions.

## Single step methods

## Multi stage methods

## Machine learning methods

## Variance heterogeneity

The details for this method have been described in the previous chapter.

To identify an individual locus that makes direct contributions to the trait variance, a statistical test is used to identify significant differences in the phenotypic variance between the groups of individuals that carry alternative alleles at the locus. When such a variance difference exists between the genotypes at a locus, the locus displays a genetic variance-heterogeneity. 


<!--chapter:end:12-GxG.Rmd-->

# Other omics

## Transcriptome-wide association studies

### cis eQTLs

### trans eQTLs

### 3-D structure of the genome

## Phenome-wide association studies

## Metabolomics

## Epigenomics

<!--chapter:end:13-Multi-omics.Rmd-->

# Quantitative trait loci mapping



<!--chapter:end:14-QTL-mapping.Rmd-->

# Additional points of interest

## Kinship matrix

### Path coefficients

## Genetic relationship matrix

## Animal models

## Phasing

### Switch rate

## Haplotyping

## Statistical power

### Quanto

### GCTA-GREML

### Mendelian Randomisation

### Twin design

### When marker is a disease susceptibility locus

### When marker is not disease susceptability locus

## Multiple comparisons

### Effective number of independant variants

## Biases

### Ascertainment

### Attenuation

### Selection

## Family studies

### Transmission disequilibrium tests

## Twin studies

## Adoption studies

## Equifinality (many genes give same trait)

## Gene dosage

### Allelic dosage

## Allelic heterogeneity

## Genetic heterogeneity

## Genomic imprinting

## Penetrance/phenocopy

## Endophenotypes

## Ploidy

## Extended phenotype

## Genome sizes

## cis-eQTL vs trans-eQTL

Compared to cis-eQTLs, trans-eQTLs typically have weaker effect size and less direct effect. As a result, they are more prone to violate assumptions in MR studies.






<!--chapter:end:15-Extra.Rmd-->

# (PART) Population Genetics {-}

# Genetic drift

<!--chapter:end:16-Genetic-drift.Rmd-->

# Mutation


## Mutation age

<!--chapter:end:17-Mutation.Rmd-->

# Selection

## Directional

## Balancing

### Frequency-dependent selection 1

### Frequency dependent selection 2


## Background selection

<!--chapter:end:18-Selection.Rmd-->

# Migration

<!--chapter:end:19-Migration.Rmd-->

# Diversity

<!--chapter:end:20-Diversity.Rmd-->

# Admixture

<!--chapter:end:21-Admixture.Rmd-->

# Linkage disequilibrium

<!--chapter:end:22-LD.Rmd-->

# In breeding and heterosis

<!--chapter:end:23-Inbreeding-and-heterosis.Rmd-->

# Assortative mating

<!--chapter:end:24-Assortative-mating.Rmd-->

# Identity

## IBS

### Long runs of IBT

## IBD

## IBT


<!--chapter:end:25-Identity.Rmd-->

# Neutral theory of molecular evolution

## Nearly neutral theory of molecular evolution

<!--chapter:end:26-Neutral-theory.Rmd-->


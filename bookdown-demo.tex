\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={A handbook for Computational Genetics},
            pdfauthor={Alfred Pozarickij},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{apalike}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}
  \title{A handbook for Computational Genetics}
  \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
  \author{Alfred Pozarickij}
  \preauthor{\centering\large\emph}
  \postauthor{\par}
  \predate{\centering\large\emph}
  \postdate{\par}
  \date{2018-08-30}

\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\chapter*{Preface}\label{preface}
\addcontentsline{toc}{chapter}{Preface}

The scope of this book is to provide an outline of computational methods
available for the analysis of genetic data.

First chapter introduces methods to infer population parameters.

Next X chapters focus on population genetics.

In this book, the amount of mathematics and statistics is kept to a
minimum. Only methods designed specifically to address issues in
genetics are shown. I have produced another book {[}insert link here{]},
which is intended to familiarise the reader with commonly used
approaches and develop some intuition behind them. By no means the list
is comprehensive and only serves as a quick guide. The internet provides
much more information regarding this topic.

Rather than providing references at the end of each chapter, I decided
to combine them into supplementary text {[}insert link here{]}.
References are arranged according to different topics discussed in this
book. I tried to do my best to cause as little confusion as possible.

Finally, don't hesitate to contact me if I have not included your
favorite method
(\href{mailto:apozarickij@gmail.com}{\nolinkurl{apozarickij@gmail.com}}).
I would be more than happy to hear about it.

\part{Quantitative
Genetics}\label{part-quantitative-genetics}

\chapter{Population parameters}\label{population-parameters}

\section{Mean}\label{mean}

\section{Variance}\label{variance}

\section{Covariance}\label{covariance}

\section{Genetic correlation}\label{genetic-correlation}

\section{Additivity}\label{additivity}

\section{Dominance/Recesivness}\label{dominancerecesivness}

\section{Codominance}\label{codominance}

\section{Infinitesimal model}\label{infinitesimal-model}

\subsection{Omnigenic model}\label{omnigenic-model}

\section{Henetic relationships by
Malecot}\label{henetic-relationships-by-malecot}

\section{Genotype simulations}\label{genotype-simulations}

\section{Phenotype simulations}\label{phenotype-simulations}

\chapter{Sequencing technologies}\label{sequencing-technologies}

The first step in any genetic analysis is to map sequence reads,
callibrate base qualities, and call variants.

Prior to mapping, evaluate base composition along reads. Calculate the
proportion of A, C, G, T bases along each read. Flag runs with evidence
of unusual patterns of base composition compared to the target genome.
Evaluate machine quality scores along reads. Calculate average quality
scores per position. Flag runs with evidence of unusual quality score
distributions. Calculate the input number of reads and number of bases
for each sequenced sample

\section{Genotype calling algorithms}\label{genotype-calling-algorithms}

\section{Sequence alignment}\label{sequence-alignment}

Sequence alignment is a method of arranging sequences of DNA, RNA, or
protein to identify regions of similarity. The similarity being
identified, may be a result of functional, structural, or evolutionary
relationships between the sequences.

If we compare two sequences, it is known as pairwise sequence alignment.
If we compare more than two sequences, it is known as multiple sequence
alignment.

\section{Sequence assembly}\label{sequence-assembly}

\section{SNP annotation}\label{snp-annotation}

\subsection{CNV annotation}\label{cnv-annotation}

\section{Gene prediction}\label{gene-prediction}

\chapter{Genome-wide association
analysis}\label{genome-wide-association-analysis}

\section{DNA processing quality
control}\label{dna-processing-quality-control}

\section{Batch effects}\label{batch-effects}

\url{https://www.bioconductor.org/packages/devel/bioc/vignettes/GWASTools/inst/doc/DataCleaning.pdf}

The overall goal of this step is to check the quality of the sample
batches. Substantial quality control is done by the genotyping centers
prior to releasing the genotype data. However, it is possible that
quality control for batches is still lower than desired. If a lower
quality batch is detected then it may be necessary to re-run the
genotyping for that batch. We can check the batch quality by comparing
the missing call rates between batches and looking for significant
allele frequency differences between batches.

\subsection{Calculation of missing call rate for samples and
SNPs}\label{calculation-of-missing-call-rate-for-samples-and-snps}

The ﬁrst step is to calculate the missing call rates for each SNP and
for each sample. A high missing call rate for a sample is often
indicative of a poorly performing sample. It has been seen that samples
from DNA that has undergone whole-genome ampliﬁcation (WGA) have a
relatively higher missing call rate. Similarly a high missing call rate
for a SNP is indicative of a problem SNP. Experience from the GENEVA
studies has shown that there seem to be a subset of SNPs from which
genotype calls are more diﬃcult to make than others. We calculate the
missing call rates in a two step process: ﬁrst the missing call rates
over all samples and SNPs are calculated, then the missing call rates
are calculated again, ﬁltering out SNPs and samples that have an initial
missing call rate greater than 0.05. The initial SNP missing call rate
over all samples is saved in the SNP annotation data ﬁle as missing.n1.
The analogous idea is applied to the samples: missing.e1 is saved in the
sample annotation ﬁle and corresponds to the missing call rate per
sample over all SNPs, excluding those SNPs with all calls missing. The
missing.n2 is calculated as the call rate per SNP over all samples whose
missing.e1 is less than 0.05. Again, similarly for the samples,
missing.e2 is calculated for each sample over all SNPs with missing.n2
values less than 0.05. It is important to remember that the Y chromosome
values should be calculated for males only, since we expect females to
have no genotype values for the Y chromosome, although an occasional
probe on the Y chromosome is called in a female. If any samples have a
high missing rate, we recommend further investigation of what may be
causing the missing calls; the samples with a missing call rate greater
than 0.05 should be ﬁltered out due to low sample quality.

\subsection{Calculation of missing call rates by
batch}\label{calculation-of-missing-call-rates-by-batch}

The missing call rate by batch is calculated to check that there are no
batches with comparatively lower call rates. Usually a``batch''is a
plate containing samples that were processed together through the
genotyping chemistry. In this case all samples were run on diﬀerent
plates (as controls for another dataset).

\subsection{Testing for allele frequency differences in
batches}\label{testing-for-allele-frequency-differences-in-batches}

In this step, the chi-square test for diﬀerences in allelic frequency is
performed between each batch individually and a pool of all the other
batches in the study. We then look at the mean χ2 statistic over all
SNPs for each batch as a function of the ethnic composition of samples
in a batch. Next we test for association between batches and population
groups, using a χ2 contingency test. Then we look at the relationship
between the ethnic composition of each batch and the previously
calculated χ2 test of allelic frequency between each batch and a pool of
the other batches. The point is to look for batches that diﬀer from
others of similar ethnic composition, which might indicate a batch eﬀect
due to genotyping artifact. In this experiment, there are only a few
batches and wide variations in race among batches, so it is diﬃcult to
interpret the results. In larger GWAS experiments, we generally observe
a U-shaped curve of allelic frequency test statistic as a function of
ethnic composition. The χ2 test is not suitable when the 2×2 tables for
each SNP have very small values. For arrays in which many SNPs have very
low minor allele frequency, Fisher's exact test is more appropriate.

\section{Sample quality control}\label{sample-quality-control}

\subsection{Cryptic relatedness}\label{cryptic-relatedness}

\subsection{Population stratification}\label{population-stratification}

Sometimes finding an association can be confounded by population
stratification. This is because a condition may be more prevalent in one
group of people than in a different group, resulting in a spurious
association between the condition or trait being tested for and any
genetic characteristics which vary between the two different groups of
people.

While it is good practice for studies to be based on as homogeneous a
group of test subjects as possible, it has been noted in {[}Price,
2006{]} that even the mild variation in genetic characteristics among
those who classify themselves as belonging to one ethnic group or
another can be problematic enough to confound a study done over
thousands of genetic markers.

Hidden population stratification may be thought of as a non-zero Fst
between unknown groupings of samples.

\subsection{Heterozygosity and missingness
outliers}\label{heterozygosity-and-missingness-outliers}

\subsection{Differential missingness}\label{differential-missingness}

\subsection{Sex chromosome anomalies}\label{sex-chromosome-anomalies}

\section{Marker quality control}\label{marker-quality-control}

\subsection{Genotyping concordance}\label{genotyping-concordance}

In genotyping studies where DNA is directly assayed for positions of
variance, concordance is a measure of the percentage of SNPs that are
measured as identical. Samples from the same individual or identical
twins theoretically have a concordance of 100\%, but due to assaying
errors and somatic mutations, they are usually found in the range of
99\% to 99.95\%. Concordance can therefore be used as a method of
assessing the accuracy of a genotyping assay platform.

\subsection{Mendelian errors}\label{mendelian-errors}

\subsection{Genotype call rate}\label{genotype-call-rate}

\subsection{Minor allele frequency}\label{minor-allele-frequency}

\subsection{Hardy-Weinberg equilibrium
outliers}\label{hardy-weinberg-equilibrium-outliers}

\subsection{Additional QC for regions like
MHC}\label{additional-qc-for-regions-like-mhc}

\subsection{Ambigious nucleotides}\label{ambigious-nucleotides}

\subsection{Non-matching nucleotides}\label{non-matching-nucleotides}

\section{X-chromosome quality
control}\label{x-chromosome-quality-control}

\section{Single marker regression}\label{single-marker-regression}

Summary statistics can be obtained using one of the following tests:
Correlation/Trend Test, Armitage Trend Test, Exact Form of Armitage
Test, (Pearson) Chi-Squared Test, (Pearson) Chi-Squared Test with Yates'
Correction, Fisher's Exact Test, Odds Ratio with Confidence Limits,
Analysis of Deviance (e.g.~different variance heterogeneity tests),
F-Test, Logistic Regression, Linear Regression.

\subsection{Allelic test}\label{allelic-test}

\subsection{Genotypic test}\label{genotypic-test}

\subsection{Additive model}\label{additive-model}

Here, the genotype is coded in terms of the number of specific allele at
a given locus.

\subsection{Dominant model}\label{dominant-model}

Here, the genotype with at least 1 copy of a specific allele at a given
locus is coded as 1 and other genotypes as 0.

\subsection{Recessive model}\label{recessive-model}

Here, the genotype with at least 2 copies of a specific allele at a
given locus is coded as 1 and other genotypes as 0.

\subsection{Categorical phenotype}\label{categorical-phenotype}

\subsection{Multi-allelic GWAS}\label{multi-allelic-gwas}

\section{Two-stage approach}\label{two-stage-approach}

\section{Haplotype GWAs design}\label{haplotype-gwas-design}

\section{Joint analysis (all independent
markers)}\label{joint-analysis-all-independent-markers}

\subsection{Genomic control}\label{genomic-control}

\subsubsection{λ1000}\label{1000}

Since λ scales with sample size, some have found it informative to
report λ1000. This is equivalent to a study of 1000 cases and 1000
controls and can be calculated by rescaling λ with 1 + (λ - 1) x (1/case
+ 1/control) x 500, where case and control refers to the number of cases
and controls respectively.

\section{Multimarker single gene-based
approaches}\label{multimarker-single-gene-based-approaches}

\url{https://cran.r-project.org/web/packages/aSPU/aSPU.pdf}

\section{VEGAS}\label{vegas}

\section{Multimarker gene-set approaches (a.k.a. pathway
analysis)}\label{multimarker-gene-set-approaches-a.k.a.-pathway-analysis}

\section{fastBAT}\label{fastbat}

\section{MAGMA}\label{magma}

\section{VEGA}\label{vega}

\section{Extensions to binary and categorical
phenotypes}\label{extensions-to-binary-and-categorical-phenotypes}

\subsection{Threshold model}\label{threshold-model}

\section{Analysis of rare variants}\label{analysis-of-rare-variants}

Check Lee et al (2014) for a review

Due to the low frequencies of rare variants, classical single marker
tests commonly used in genome-wide association studies (GWAS) for
studying common variants effects are not applicable. In view of the lack
of power of single marker analysis of rare variants, methods
investigating rare variation are typically region-based tests where one
tests for the cumulative effects of the rare variants in a region. These
region-based methods can be broadly classified into three classes:
burden tests, non-burden tests and hybrid of the two. The key difference
between burden and non-burden tests is how the cumulative effects of the
rare variants are combined for association testing. For the commonly
used simple burden tests, one summarizes the rare variants within a
region as a single summary genetic burden variable, e.g.~the total
number of rare variants in a region, and tests its association with a
trait. Burden tests implicitly assume all the rare variants in the
region under consideration are causal and are associated with the
phenotype in the same direction and magnitude. Hence, they all share the
limitation of substantial power loss when there are many non-causal
genetic variants in a region and/or when there are both protective and
harmful variants. Several region-based non-burden tests have been
proposed by aggregating marginal test statistics (Neale et al., 2011;
Basu and Pan, 2011; Lin and Tang, 2011). One such test is the sequence
kernel association test (SKAT) (Wu et al., 2011), where one summarizes
the rare variants in the region using a kernel function, and then test
for association with the trait of interest using a variance component
score test. SKAT is robust to the signs and magnitudes of the
associations of rare variants with a trait. It is more powerful than the
burden tests when the effects are in different directions or the
majority of variants in a region are null, but is less powerful than
burden tests when most variants in a region are causal and the effects
are in the same direction. Several hybrids of the two methods have been
proposed to improve test power and robustness (Lee et al., 2012; Derkach
et al., 2013; Sun et al., 2013).

\subsection{Collapsing methods based on pooling multiple rare variants
(burden or adaptive burden
tests)}\label{collapsing-methods-based-on-pooling-multiple-rare-variants-burden-or-adaptive-burden-tests}

\subsubsection{Sum test}\label{sum-test}

The most powerful multi-marker test when there are no causal variants
with effects in opposite directions and when there are few or no
non-causal RVs. Otherwise, it suffers from substantial loss of power.

\subsubsection{Cohort Allelic Sums test
(CAST)}\label{cohort-allelic-sums-test-cast}

\subsubsection{Combined Multivariate Collapsing
(CMC)}\label{combined-multivariate-collapsing-cmc}

\subsubsection{Weighted Sum test (WSS)}\label{weighted-sum-test-wss}

\subsubsection{Kernel Based Adaptive Cluster
(KBAC)}\label{kernel-based-adaptive-cluster-kbac}

\subsubsection{Replication Based Test
(RBT)}\label{replication-based-test-rbt}

\subsubsection{ARIEL test}\label{ariel-test}

\subsubsection{The EREC test}\label{the-erec-test}

\subsection{Methods treating rare variant effects as random
(Variance-component
tests)}\label{methods-treating-rare-variant-effects-as-random-variance-component-tests}

\subsubsection{The SSU approach}\label{the-ssu-approach}

Has good power in the presence of opposite association directions and
small fraction of causal RVs.

\subsubsection{C-alpha test}\label{c-alpha-test}

\subsubsection{SKAT}\label{skat}

Has good power in the presence of opposite association directions and
non-causal RVs. It was recently suggested that using SKAT in the
presence of RVs and common variants (CVs) may be less optimal because
RVs are weighted to have much more importance than CVs (Ionita-Laza et
al., 2013).

\subsection{Methods based on model
selection}\label{methods-based-on-model-selection}

The model-selection approaches perform in the middle of random eﬀect and
collapsing methods. One issue common to model-selection methods is that
model selection approaches use dimension-reduction strategies to
substantially reduce the number of parameters one would require to ﬁt
these large number of RVs. Hence, any model we can construct will never
be the true model that generated the data we observe. In other words,
the set of models is clearly misspeciﬁed, and model selection is best
seen as a way of approximating, rather than identifying, full reality
(Burnham and Anderson (2002), pp.~20-23).

\subsubsection{Seq-aSum}\label{seq-asum}

\subsubsection{Seq-aSum-VS}\label{seq-asum-vs}

The Seq-aSum-VS approach classiﬁes RVs based on the direction of
association (`+1' for positive association, `-1' for negative
association and `0' for no association) and implements a sequential
variable selection scheme to select the best model for association
between the SNP-set and the disease. The only diﬀerence between the
Seq-aSum approach and the Seq-aSum-VS approach is that the variable
selection (`0' allocation for a variant) is not implemented in the
former. The Seq-aSum-VS approach starts with putting all the RVs in the
`+1' group and proceeds by moving each RV sequentially to the other two
groups and ﬁnally chooses the allocation (`+1',`-1', or `0' ) with
highest likelihood to the RV. The process of choosing the best model in
Basu and Pan (2011)'s method can be compared to a stepwise regression,
where one may not always ﬁnd the best model due to this selection
scheme. This is especially true if a particular allocation results in a
slightly higher likelihood than the other two allocations. In this case,
choosing the allocation with highest likelihood for a SNP might not be
optimal, rather it might be more eﬃcient to allow multiple allocations
for a RV and construct a test that takes into account multiple plausible
models for the disease-RV association. Moreover, the performance of the
sequential search often depends on the ordering of the variants in this
search mechanism. A model-averaging approach could potentially reduce
the dependency on the ordering of the variants in this sequential
search.

\subsubsection{Variable Threshold Test
(VT)}\label{variable-threshold-test-vt}

\subsubsection{RARECOVER}\label{rarecover}

\subsubsection{Selective grouping
method}\label{selective-grouping-method}

\subsubsection{Step-Up}\label{step-up}

\subsection{Combination of collapsing and random effects
methods}\label{combination-of-collapsing-and-random-effects-methods}

According to Basu and Pan (2011), the model selection methods,
especially Seq-aSum-VS approach, performed very well when there were
both protective and deleterious causal RVs and very few non-causal RVs,
but the performance of the Seq-aSum-VS approach was not very impressive
in the presence of a moderate or large number of non-causal RVs. These
and other ﬁndings (Basu and Pan, 2011) have led to combining the
strengths of collapsing and random eﬀect methods.

\subsubsection{SKAT-O}\label{skat-o}

\subsubsection{SKAT-C}\label{skat-c}

\subsubsection{Fisher method}\label{fisher-method}

\subsubsection{MiST}\label{mist}

\subsection{EC test}\label{ec-test}

Exponentially combines score statistics. Powerful when a very small
proportion of variants are causal.

\subsection{Family-based tests}\label{family-based-tests}

\url{https://www.omicsonline.org/open-access/literature-reviews-on-methods-for-rare-variant-association-studies-2161-0436-1000133.pdf}

\section{Analysis of X, Y and mitochondrial
chromosomes}\label{analysis-of-x-y-and-mitochondrial-chromosomes}

\subsection{Dosage compensation}\label{dosage-compensation}

\section{Analysis of copy number
variants}\label{analysis-of-copy-number-variants}

\subsection{Common variation}\label{common-variation}

\subsection{Analysis of rare
variants}\label{analysis-of-rare-variants-1}

\section{Analysis of multi-ethnic
samples}\label{analysis-of-multi-ethnic-samples}

\section{Analysis of indirect genetic
effects}\label{analysis-of-indirect-genetic-effects}

\section{Exome analysis}\label{exome-analysis}

\section{Whole-genome analysis}\label{whole-genome-analysis}

\subsection{Deep whole genome
sequencing}\label{deep-whole-genome-sequencing}

Can only be applied to limited numbers of samples Most complete
ascertainment of variation

\subsection{Low coverage whole genome
sequencing}\label{low-coverage-whole-genome-sequencing}

Can be applied to moderate numbers of samples Very complete
ascertainment of shared variation Less complete ascertainment of rare
variants

\section{Analysis of multiple traits}\label{analysis-of-multiple-traits}

\section{Mixed-model association
analysis}\label{mixed-model-association-analysis}

\subsection{EMMAX}\label{emmax}

\subsection{Fast-LMM}\label{fast-lmm}

\subsection{GEMMA}\label{gemma}

\subsection{BOLT-LMM}\label{bolt-lmm}

\section{Penalized regression GWAS}\label{penalized-regression-gwas}

\section{Bayesian GWAS}\label{bayesian-gwas}

\section{Machine learning for GWAS}\label{machine-learning-for-gwas}

\section{Expected increase in GWAS loci with sample
size}\label{expected-increase-in-gwas-loci-with-sample-size}

\section{The joint effect of genotypes over all
traits}\label{the-joint-effect-of-genotypes-over-all-traits}

\chapter{Heritability}\label{heritability}

\section{Realized heritability}\label{realized-heritability}

\subsection{Evolvability}\label{evolvability}

\subsection{Reliability}\label{reliability}

\section{Twin studies}\label{twin-studies}

\section{Haseman-Elston regression}\label{haseman-elston-regression}

\section{GREML}\label{greml}

\section{GREML in family data}\label{greml-in-family-data}

\section{GREML in WGS or imputed
data}\label{greml-in-wgs-or-imputed-data}

\subsection{GREMLd}\label{gremld}

\subsection{Bivariate GREML}\label{bivariate-greml}

\section{LD-score regression}\label{ld-score-regression}

\section{LDAK}\label{ldak}

\section{Heritability by chromosome, MAF bin, or functional
category}\label{heritability-by-chromosome-maf-bin-or-functional-category}

\chapter{Genomic prediction}\label{genomic-prediction}

\section{Unweighted sum of risk
alleles}\label{unweighted-sum-of-risk-alleles}

\section{Polygenic risk scores}\label{polygenic-risk-scores}

\section{Gene-based polygenic score
(POLARIS)}\label{gene-based-polygenic-score-polaris}

\section{Pathway-based polygenic risk
score}\label{pathway-based-polygenic-risk-score}

\section{LD adjusted PRS}\label{ld-adjusted-prs}

\subsection{LDpred with functional
annotation}\label{ldpred-with-functional-annotation}

\section{Annopred}\label{annopred}

\section{Pleiopred}\label{pleiopred}

\section{Prediction including GxE}\label{prediction-including-gxe}

\section{BLUP}\label{blup}

\subsection{GBLUP}\label{gblup}

\subsection{sBLUP}\label{sblup}

\section{Bayesian Zoo}\label{bayesian-zoo}

\subsection{B}\label{b}

\subsection{C}\label{c}

\subsection{S}\label{s}

\subsection{N}\label{n}

\subsection{NS}\label{ns}

\subsection{R}\label{r}

\section{Reproducing kernel Hilbert
space}\label{reproducing-kernel-hilbert-space}

\section{Machine learning methods}\label{machine-learning-methods}

\chapter{Pleiotropy}\label{pleiotropy}

\section{Fisher's geometric model}\label{fishers-geometric-model}

\section{Direct}\label{direct}

\section{Indirect}\label{indirect}

\chapter{Pathway-analysis}\label{pathway-analysis}

\chapter{Functional annotation}\label{functional-annotation}

\chapter{Causal inference}\label{causal-inference}

\section{Gene-knockout}\label{gene-knockout}

\section{Conditioning}\label{conditioning}

Adding additional SNPs as covariates

\section{COJO}\label{cojo}

\section{mtCOJO}\label{mtcojo}

\section{Finemapping}\label{finemapping}

\section{Mendelian Randomization}\label{mendelian-randomization}

Mendelian Randomization relies on three assumptions about the
instruments:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  They must be sufficiently strongly associated with the exposure.
\item
  They should not be associated with any confounder of the
  exposure-outcome relationship.
\item
  They should be associated with the outcome only through the exposure.
\end{enumerate}

Violation of any ofthese assumptions often through pleiotropy would lead
to biased estimates of the causal effect and potential false positives.
The second assumption is the most difficult to verify because
confounding factors are often unknown, whereas the last assumption can
only be partially verified at best if SNPs, exposures and outcome data
are available from the same (large) sample, a condition not fulfilled
for two-sample MR.

These assumptions imply that the genetic variants (IVs) have a causal
effect on the outcome only via the risk factor. While the first
assumption can be easily verified, the second one is impossible to
confirm as not all confounders are known, and the third requires
instrument-exposure-outcome data measured in the same sample and is
often violated by pleiotropy. One (ideal) way to guard against the
violation of the third assumption is to use as many IVs possible, as the
pleiotropic effect of each marker will cancel each other out under the
INSIDE assumption (instrument strength independent of the strength of
the pleiotropy).

Cochran's Q test can be used in order to test for the presence of
pleiotropy.

\subsection{Summary data-based MR
(SMR)}\label{summary-data-based-mr-smr}

SMR can be used to test whether the effects of genetic variants on a
phenotype are mediated by gene expression. The method is based on a
single genetic variant.

\subsection{Generalised summary-data-based MR (GSMR) and
HEIDI}\label{generalised-summary-data-based-mr-gsmr-and-heidi}

GSMR was developed to overcome the issue of unaccounted pleiotropy in
SMR method. This method performs a MR analysis with multiple independent
SNPs as instrumental variables.

\subsection{Joint analysis of GWAS and eQTL
data}\label{joint-analysis-of-gwas-and-eqtl-data}

It is common in GWAS studies to identify variants that are located in
genomic regions thought to be involved in regulation of gene expression.
In order to improve power from GWAS studies, a method involving joint
analysis of GWAS and eQTL data was proposed. This approach superceeds
previous TWAS methods by allowing to account for pleiotropy in a
Mendelian Randomization framework.

Two things are needed in order to carry out this test: summary-level
data and pair-wise SNP LD information.

The method was developed after realisation that many pleiotropic effects
are mediated through the expression levels of neighbouring genes; hence
including other genes as exposures should reduce MR assumption
violation, while improving power. Furthermore, such approach might be
able to better distinguish the causal effects of genes with correlated
expression levels.

As any other method, this approach suffers from several limitations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  The putative causal associations reported in this study are not
  definitive. They provide a prioritized list of candidate genes for
  future follow-up studies and also shed light on possible biological
  mechanisms of complex traits.
\item
  Currently, eQTL data is available for 15K egenes, which substantially
  decreases power to detect enrichment of prioritized gene-set in
  relevant pathways and regulatory networks.
\item
  Violations of MR assumptions. In particular, horizontal pleiotropy and
  indirect effects of the instruments on the exposures can substantially
  bias causal effect estimates.
\end{enumerate}

Because the study requires summary statistics and LD pattern, it is
possible to extend the method to include other omics information.

\subsection{Tissue-specific MR}\label{tissue-specific-mr}

Since many traits manifest themselves only in certain tissues, it is
important to integrate data from the tissue of interest for the studied
phenotype when trying to interpret GWAS results using gene expression as
an intermediate phenotype.

\chapter{Combining multiple datasets}\label{combining-multiple-datasets}

\section{Meta-analysis}\label{meta-analysis}

\subsection{Meta-analysis of gene-level associations
(common)?}\label{meta-analysis-of-gene-level-associations-common}

\subsection{Meta-analysis of rare
variants}\label{meta-analysis-of-rare-variants}

RAREMETAL and RAREMETALWORKER

\section{Mega-analysis}\label{mega-analysis}

\chapter{Gene-environment
interaction}\label{gene-environment-interaction}

It is generally accepted that complex diseases are caused by an
interplay of genetic and environmental factors, creating a challenge for
understanding the disease mechanisms. Understanding the interplay
between genes and environmental factors is important, as genes do not
operate in isolation but rather in complex networks and pathways
influenced by environmental factors. Identification of gene-environment
interactions has important implications for understanding underlying
disease etiology and developing disease prevention and intervention
strategies. In addition to providing insights into disease etiology,
exploiting gene-environment (G-E) interaction can help discover novel
susceptibility loci for complex diseases, where genetic effects are
modified and masked by the effects of environmental factors. From a
public health perspective, G-E interaction is useful because findings
based on interactions can help develop strategies for targeted
intervention; conducting an intervention focusing on a subset of the
population identified by G-E interactions can provide efficiency in
disease prevention. There are several challenges of G-E interaction
analysis that include replication issues. While more powerful
statistical methods for detecting interactions are helpful, ultimately
studies with larger sample sizes are needed to identify interactions
through consortium-based studies to achieve adequate power for G-E
analysis.

This chapter aims to describe methods that extend single marker
regression by taking into consideration the effect of gene-environment
interaction.

\section{Single step methods}\label{single-step-methods}

There are several disease risk models for the joint effects of G and E,
and interpretations of G-E interactions depend on the underlying disease
risk models.

\subsection{Case-control}\label{case-control}

\subsection{Prospective likelihood-based
approach}\label{prospective-likelihood-based-approach}

\subsection{Retrospective likelihood
approach}\label{retrospective-likelihood-approach}

To address the limitations of case-only approaches that can only test
for multiplicative interactions (not for the main effects of G and E),
Umbach and Weinberg (1997) generalized the case-only design idea to use
a log-linear model based on case-control data. They showed the
maximum-likelihood estimates for all parameters of a logistic regression
model can be obtained using a log-linear model. Along the same line,
Chatterjee and Carroll developed a general method using a retrospective
likelihood that exploits the G-E independence assumption to test for
multiplicative interaction, but can use both cases and controls to
estimate all of the parameters in a general logistic regression model.
Basically, this method employs a retrospective likelihood that
explicitly models the conditional probability of G given E mediated by
an association parameter θ that can be constrained to be zero when the
G-E independence assumption holds. This likelihood can be used for
testing both multiplicative and additive interactions; recently, Han et
al. developed a likelihood ratio test that exploits the G-E independence
assumption using a retrospective likelihood. Their numerical
investigation of power suggests that the incorporation of the
independence assumption can enhance the efficiency of the test for
additive interaction by 2- to 2.5-fold.

\subsubsection{Multiplicative scale}\label{multiplicative-scale}

A multiplicative model incorporating GxE effects is one of the most
commonly used models via logistic regression: logit(Pr(\emph{D} =
1\textbar{}\emph{G},\emph{E})) = \emph{βo} + \emph{βgG} + \emph{βeE} +
\emph{βgeGE}, where \emph{G} is a genotype of a SNP, \emph{E} is an
environmental risk factor, and \emph{D} is the disease status.

Assuming binary factors for both G and E, a 2 × 2 table for a disease
risk for each combination of G and E values can be constructed based on
this model (Table X).

\subsubsection{Additive scale}\label{additive-scale}

An additive model is shown as logit(Pr(\emph{D} =
1\textbar{}\emph{G},\emph{E})) = \emph{bo} + \emph{bgG} + \emph{beE} +
\emph{bgeGE}, where the effects of G and E are additive on the disease
risk scale, but not on the logit scale.

\subsection{Case-only}\label{case-only}

This design depends on an assumption of G--E independence in the
underlying population. Under the assumption of G-E independence in the
underlying population (i.e., controls), a multiplicative interaction
test statistic becomes equivalent to testing the association between G
and E among cases. One major limitation of the case-only design is that
while the case-only method has improved power over the traditional
methods when G and E are independent in the underlying population, this
method has an increased type I error if the independence assumption is
violated. In addition, the regression parameters for the main effects of
G and E cannot be estimated using this method because the case-only test
is only for evaluating a multiplicative interaction.

\subsection{Empirical Bayes and Bayesian Model
Averaging}\label{empirical-bayes-and-bayesian-model-averaging}

\section{GxE in the context of family
studies}\label{gxe-in-the-context-of-family-studies}

\section{Multi stage methods}\label{multi-stage-methods}

Several approaches exist. In general, these methods suggest selecting a
subset of SNPs based on the marginal effects of SNPs or G-E correlation
tests in the first stage and conducting standard G-E interaction tests
in the second stage, where the independence between the test statistics
used in the two stages is required to provide a valid screening
procedure.

For calculating power for G-E interactions, the powerGWASinteraction R
package is available
(\url{https://cran.r-project.org/web/packages/powerGWASinteraction/index.html}),
which includes a power calculation tool for four two-stage screening and
testing procedures.

\section{Joint tests}\label{joint-tests}

\subsection{Gene-based}\label{gene-based}

\section{Set-based interaction tests}\label{set-based-interaction-tests}

There are multiple reasons for using set-based gene-environment
interaction tests.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Multiple comparison adjustments for a large number of markers across
  the genome could result in power loss.
\item
  Closely located SNPs are correlated because of linkage disequilibrium.
  Multiple tests for GxE in these single-marker-based GxE models are
  even more dependent, as interaction terms in these models share the
  same environmental variable. Dependence among multiple tests can
  result in incorrect Type 1 error rates and causes bias in standard
  multiple comparison adjustments and this bias is often difficult to
  correct.
\item
  The single-marker GxE test does not interrogate the joint effects of
  multiple SNPs that have similar biological functions. When the main
  effects of multiple SNPs in a set are associated with a disease/trait,
  the classical single marker regression interaction test can be biased.
\end{enumerate}

Lin et al. (2013) developed a method to analyse GxE for a set of markers
using generalized linear mixed models. The method tests for SNP-set by
environment interactions using a variance component test, and because a
set of variants will likely be correlated, the main SNP effect estimates
under the null hypothesis are obtained using ridge regression. Their
software is called GESAT. Here, they model GxE effects as random, as
opposed to the classical approach of treating \emph{βj}'s as fixed
effects followed by a test with \emph{p} degrees of freedom. The latter
approach can suffer from power loss when \emph{p} is moderate/large, and
numerical difficulties when some genetic markers in the set are in high
LD. The model allows to adjust for the main effects of all SNPs while
simultaneously testing for the interactions between the SNPs in the
region and environmental variable. For unbalanced designs when a binary
environmental exposure has a low frequency in one category, GESAT is
most advantageous over single marker regression GxE test. Such
unbalanced designs can occur due to case--control sampling and the
strong association of an environmental factor with disease. When the
effect size is modest, GESAT performs better that single marker
regression GxE test, but when the effect size is strong, the opposite is
true. Their simulations suggest that the power of GESAT seems fairly
robust to the dependence between G and E.

The same approach can be applied to investigating various other
biological problems. For example, we can test for the interactions
between gene expressions in a pathway or network and an environmental
variable by simply replacing G by gene expressions in a gene-set.

Existing methods for assessing common variants by environment
interactions such as Gene-Environment Set Association Test (GESAT) (Lin
et al., 2013) have several limitations when applied for rare variants.
GESAT estimates the main effects of the common variants by applying a L2
penalty on the genotypes scaled to unit variance; this assumes that the
main effects of the scaled genotypes are comparable in magnitudes, which
may not hold in the case of rare variants. GESAT also assumes that the
regression coefficients of the rare variants by environment interactions
are independent of each other, and suffers from power loss when most
rare variants in a gene interact with the environmental factor and the
interaction effects have the same direction.

Similar idea from GESAT was later extended and applied to analyse rare
variants. GESAT have several limitations when applied for rare variants.
GESAT estimates the main effects of the common variants by applying a L2
penalty on the genotypes scaled to unit variance; this assumes that the
main effects of the scaled genotypes are comparable in magnitudes, which
may not hold in the case of rare variants. GESAT also assumes that the
regression coefficients of the rare variants by environment interactions
are independent of each other, and suffers from power loss when most
rare variants in a gene interact with the environmental factor and the
interaction effects have the same direction. The new proposed test iSKAT
is optimal in a class of variance component tests and is powerful and
robust to the proportion of variants in a gene that interact with
environment and the signs of the effects. This test properly controls
for the main effects of the rare variants using weighted ridge
regression while adjusting for covariates.

A naive approach to assess rare variants by environment interactions is
to extend the burden test by fitting a model with both the summary
genetic burden variable, environment, and their interaction, and
performing a one degree of freedom test for the interaction. However,
when there are multiple causal variants with their main effects having
different magnitudes and/or signs, such a burden rare variant by
environment test fails, and may lead to inflated Type 1 error rates.
This is because adjusting for the main effects of the multiple causal
variants using a single summary genetic burden variable is
inappropriate. Likewise, a naive approach to assess rare variants by
environment interactions using SKAT by including the main effects of
rare variants as part of covariates and applying SKAT to the interaction
terms is problematic. This is because SKAT only allows adjustment of a
small number of covariates and cannot handle the presence of a large
number of rare variants in a region. Furthermore since the rare variants
are observed in low frequency, a model with all the rare variants as
main effects will be highly unstable and may not even converge.

Both GESAT and iSKAT are able to incorporate multiple environmental
variables.

No gene-based GxE test exists for the analysis of the sex chromosomes as
of writing this text.

The rareGE R package
(\url{https://www.hsph.harvard.edu/han-chen/software/}) provides various
functions for detecting G-E interaction as well as for testing the joint
effect of a gene and G-E interaction under a set-based framework. The
SIMreg R package
(\url{http://www4.stat.ncsu.edu/~jytzeng/software_simreg.php}) offers
functions for testing a set-based G-E interaction by using genetic
similarity to aggregate information across SNPs, and incorporating
adaptive weights depending on allele frequencies to accommodate rare and
common variants.

\url{https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.12428}

\url{https://academic.oup.com/biostatistics/article-abstract/18/1/119/2555344?redirectedFrom=fulltext}

\section{Combining multiple
environments}\label{combining-multiple-environments}

\subsection{Multi-trait multi-GxE
tests}\label{multi-trait-multi-gxe-tests}

\section{Variance heterogeneity}\label{variance-heterogeneity}

All methods described in this chapter so far conduct a location (mean)
based test. In other words, the main concern is whether there is a
difference in mean effect between different genotypes. Testing for scale
(variance) heterogeneity, prior to the main inference of location
parameters, is additional method to evaluate the assumption of
homoscedasticity in linear regression. This is true when the interacting
variable was not collected and the interaction term may not be directly
modeled or when a phenotype was transformed. Therefore, the analysis of
variances of the trait is based on SNP information only.

Presence of interaction between a genotype and certain factor is
expected to alter the trait's variance in the group of subjects carrying
such genotype.

Can the shift in variance be caused by multi-allelic loci?

\subsection{Levene's test}\label{levenes-test}

Levene's test (Levene, 1960) is known for its simplicity and robustness
to modeling assumptions, and it is perhaps the most popular method for
evaluating variance heterogeneity between k groups. More recently it has
been employed as an indirect test for interaction effects.

\subsection{Bartlett's test}\label{bartletts-test}

\(T^2 = \frac{(N-k) \sum_{j=0}^{k-1} n_j(Z_j.-Z_..)^2}{(k-1)\sum_{i=1}^{N}(Z_i-Z_gi.)}\)

\subsection{Bartlett's test with prior rank transformation to
normality}\label{bartletts-test-with-prior-rank-transformation-to-normality}

\subsection{Generalized Levene's scale
tests}\label{generalized-levenes-scale-tests}

The Levene's test for variance heterogeneity was later expanded to
include sample correlation and group membership uncertainty (genotype
imputation probabilities). Following a two-stage regression framework,
it was shown that the least absolute deviation regression must be used
in the stage 1 analysis to ensure a correct asymptotic χ2k−1/(k−1)
distribution of the generalized scale (gS) test statistic.

gS has good type 1 error control in the presence of sample correlation,
small samples, unbalanced group sizes, and non-symmetric outcome data.

Same study showed that the least absolute deviation (LAD) regression
approach to obtain group-median-adjusted residuals is needed to ensure
robust performance of gS (and possibly LAD should be used in all scale
dependent tests).

Several improvements including adjustment for covariates could be
further explored (check original paper)

\subsection{Two-step screening on residual variance
heterogeneity}\label{two-step-screening-on-residual-variance-heterogeneity}

\subsubsection{VH}\label{vh}

\subsubsection{YGVH}\label{ygvh}

One caviet involving VH tests is that the absence of VH for a SNP can
not be interpreted as the absence of the SNP involvment of the SNP in
the interaction network.

\subsection{Conditional quantile
regression}\label{conditional-quantile-regression}

In contrast to OLS regression, quantile regression tests for the effect
differences across the range of quantiles. More specifically,
conditional quantile regression (CQR), can be used to model effect size
changes across the sample distribution. This method is similar to other
varaince heterogeneity methods in a way that does not require
interacting effects to be known and hence included in the model. The
downside of this is that further investigation is required to identify
environmental factors causing statistical interactions.

\subsection{Sliced inverse regression}\label{sliced-inverse-regression}

Jiang and Liu, 2014

\subsection{Variance heterogeneity for related
individuals}\label{variance-heterogeneity-for-related-individuals}

\section{RELIEF and other machine learning
tools}\label{relief-and-other-machine-learning-tools}

\subsection{Multidimensionality
reduction}\label{multidimensionality-reduction}

\section{Meta-analytic GxE
approaches}\label{meta-analytic-gxe-approaches}

\section{Gene-environment
correlation}\label{gene-environment-correlation}

\section{Other challanges}\label{other-challanges}

There are several challenges of G-E interaction analysis. One main
challenge is replication issues. While various GWAS findings of the main
effects of SNPs have been replicated by independent studies for many
complex diseases (\url{http://www.ebi.ac.uk/gwas/}), relatively few
interactions have been reproduced. It is likely that the sample sizes of
GWAS that have required measurements on environmental exposures are not
yet adequate to reliably identify G-E interactions of modest magnitude.
In addition, differences in the underlying distribution of environmental
exposures across various studies as well as difficulties in accurately
measuring environmental exposures can also lead to reduced power of
detecting G-E interactions. While more powerful statistical methods for
detecting interactions are helpful, ultimately studies with larger
sample sizes are needed to identify interactions (e.g., through
consortium-based studies) to achieve adequate power for G-E analysis. A
reasonable goal for the future will be to at least identify parsimonious
models that adequately describe the risks of diseases associated with a
combination of genetic and environmental risk factors. The lack of
reporting of interaction in current studies so far indicates that linear
logistic models, i.e., multiplicative models, in general may be a good
starting point for building models for evaluating the joint effects of
genetic and environmental factors.

\chapter{Gene-gene interaction}\label{gene-gene-interaction}

When the combined phenotypic effect of alleles at two or more loci
deviates from the sum of their individual effects, this is referred to
as a genetic interaction, or epistasis. There are some situations where
data and theory have suggested that it might be particularly important
to account for genetic interactions. One is when the aim is to predict
the phenotypes of individuals on the basis of their genotype. If
interactions lead to extreme phenotypes for some genotypes, these
phenotypes are unlikely to be captured by additive models, particularly
if they are rare. Another case is the prediction of long-term selection
response. Under an additive model, both the additive variance and the
response are expected to be nearly constant over the first few
generations. As generations proceed, allele frequencies change to alter
the additive variance and, consequently, the response to selection. This
change is more rapid for traits regulated by fewer loci with larger
effects than for traits regulated by many loci with smaller effects. It
is known that genetic interactions can contribute to the additive
genetic variance in a population. The contribution, however, varies
depending on the joint allele frequencies across all the interacting
loci as well as on the types and strengths of the genetic interactions.
The changes in the additive variance, and hence the response, during
ongoing selection are therefore more complex in the presence of genetic
interactions.

Most genetic variance in a population is expected to be additive even in
the presence of extensive epistasis. The lack of empirical knowledge
about the pervasiveness and strength of epistasis in the genetic
architectures of complex traits makes it largely unknown how much of the
observed additive genetic variance in quantitative genetics studies is
due to genetic interactions.

\section{Single step methods}\label{single-step-methods-1}

\section{Multi stage methods}\label{multi-stage-methods-1}

\section{Machine learning methods}\label{machine-learning-methods-1}

\section{Variance heterogeneity}\label{variance-heterogeneity-1}

The details for this method have been described in the previous chapter.

To identify an individual locus that makes direct contributions to the
trait variance, a statistical test is used to identify significant
differences in the phenotypic variance between the groups of individuals
that carry alternative alleles at the locus. When such a variance
difference exists between the genotypes at a locus, the locus displays a
genetic variance-heterogeneity.

\chapter{Other omics}\label{other-omics}

\section{Transcriptome-wide association
studies}\label{transcriptome-wide-association-studies}

\subsection{cis eQTLs}\label{cis-eqtls}

\subsection{trans eQTLs}\label{trans-eqtls}

\subsection{3-D structure of the
genome}\label{d-structure-of-the-genome}

\section{Phenome-wide association
studies}\label{phenome-wide-association-studies}

\section{Metabolomics}\label{metabolomics}

\section{Epigenomics}\label{epigenomics}

\chapter{Quantitative trait loci
mapping}\label{quantitative-trait-loci-mapping}

\chapter{Additional points of
interest}\label{additional-points-of-interest}

\section{Kinship matrix}\label{kinship-matrix}

\subsection{Path coefficients}\label{path-coefficients}

\section{Genetic relationship matrix}\label{genetic-relationship-matrix}

\section{Animal models}\label{animal-models}

\section{Phasing}\label{phasing}

\subsection{Switch rate}\label{switch-rate}

\section{Haplotyping}\label{haplotyping}

\section{Statistical power}\label{statistical-power}

\subsection{Quanto}\label{quanto}

\subsection{GCTA-GREML}\label{gcta-greml}

\subsection{Mendelian Randomisation}\label{mendelian-randomisation}

\subsection{Twin design}\label{twin-design}

\subsection{When marker is a disease susceptibility
locus}\label{when-marker-is-a-disease-susceptibility-locus}

\subsection{When marker is not disease susceptability
locus}\label{when-marker-is-not-disease-susceptability-locus}

\section{Multiple comparisons}\label{multiple-comparisons}

\subsection{Effective number of independant
variants}\label{effective-number-of-independant-variants}

\section{Biases}\label{biases}

\subsection{Ascertainment}\label{ascertainment}

\subsection{Attenuation}\label{attenuation}

\subsection{Selection}\label{selection}

\section{Family studies}\label{family-studies}

\subsection{Transmission disequilibrium
tests}\label{transmission-disequilibrium-tests}

\section{Twin studies}\label{twin-studies-1}

\section{Adoption studies}\label{adoption-studies}

\section{Equifinality (many genes give same
trait)}\label{equifinality-many-genes-give-same-trait}

\section{Gene dosage}\label{gene-dosage}

\subsection{Allelic dosage}\label{allelic-dosage}

\section{Allelic heterogeneity}\label{allelic-heterogeneity}

\section{Genetic heterogeneity}\label{genetic-heterogeneity}

\section{Genomic imprinting}\label{genomic-imprinting}

\section{Penetrance/phenocopy}\label{penetrancephenocopy}

\section{Endophenotypes}\label{endophenotypes}

\section{Ploidy}\label{ploidy}

\section{Extended phenotype}\label{extended-phenotype}

\section{Genome sizes}\label{genome-sizes}

\section{cis-eQTL vs trans-eQTL}\label{cis-eqtl-vs-trans-eqtl}

Compared to cis-eQTLs, trans-eQTLs typically have weaker effect size and
less direct effect. As a result, they are more prone to violate
assumptions in MR studies.

\part{Population Genetics}\label{part-population-genetics}

\chapter{Genetic drift}\label{genetic-drift}

\chapter{Mutation}\label{mutation}

\section{Mutation age}\label{mutation-age}

\chapter{Selection}\label{selection-1}

\section{Directional}\label{directional}

\section{Balancing}\label{balancing}

\subsection{Frequency-dependent selection
1}\label{frequency-dependent-selection-1}

\subsection{Frequency dependent selection
2}\label{frequency-dependent-selection-2}

\section{Background selection}\label{background-selection}

\chapter{Migration}\label{migration}

\chapter{Diversity}\label{diversity}

\chapter{Admixture}\label{admixture}

\chapter{Linkage disequilibrium}\label{linkage-disequilibrium}

\chapter{In breeding and heterosis}\label{in-breeding-and-heterosis}

\chapter{Assortative mating}\label{assortative-mating}

\chapter{Identity}\label{identity}

\section{IBS}\label{ibs}

\subsection{Long runs of IBT}\label{long-runs-of-ibt}

\section{IBD}\label{ibd}

\section{IBT}\label{ibt}

\chapter{Neutral theory of molecular
evolution}\label{neutral-theory-of-molecular-evolution}

\section{Nearly neutral theory of molecular
evolution}\label{nearly-neutral-theory-of-molecular-evolution}

\bibliography{packages,book}


\end{document}
